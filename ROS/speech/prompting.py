import sys
import os
import logging
import openai
from dotenv import load_dotenv
from search_chromadb import search_hospital_info
from weather_api import get_weather_with_context
from hospital_google_search import google_search
from tavily_search import tavily_search, optimize_query
import re

load_dotenv()
API_KEY = os.environ.get('API_KEY')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.DEBUG, format="%(asctime)s [%(levelname)s] %(message)s")

# OpenAI API í‚¤ ì„¤ì •
client = openai.OpenAI(api_key=API_KEY)

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
history = []

# ì‘ë‹µ í˜•íƒœ í›„ì²˜ë¦¬ : ì‘ë‹µì˜ ë§ˆì§€ë§‰ ë§ˆì¹¨í‘œê¹Œì§€ì˜ ë‚´ìš©ë§Œ ë°˜í™˜
def trim_to_complete_sentence(response_text):
    last_period_index = response_text.rfind(".")

    if last_period_index != -1:
        return response_text[: last_period_index + 1]  # ë§ˆì¹¨í‘œ í¬í•¨í•œ ë¶€ë¶„ê¹Œì§€ë§Œ ë°˜í™˜
    return response_text  # ë§ˆì¹¨í‘œê°€ ì—†ìœ¼ë©´ ì›ë¬¸ ê·¸ëŒ€ë¡œ ë°˜í™˜

# ëŒ€í™”í˜• ì±—ë´‡ ìƒì„± í•¨ìˆ˜
def generate_response(query, search_results, external_search):
    logging.debug(f"ì‚¬ìš©ì ì§ˆë¬¸ ìˆ˜ì‹ : {query}")
    logging.debug(f"ê²€ìƒ‰ëœ ë³‘ì› ì •ë³´ ì›ë³¸: {search_results}")

   # ë‚ ì”¨ ì§ˆë¬¸ ê°ì§€
    if "ë‚ ì”¨" in query or "ê¸°ì˜¨" in query:
        weather_info = get_weather_with_context("Seoul")  # ì„œìš¸ë¡œ ê³ ì •
        return f"ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ëŠ” {weather_info} ì…ë‹ˆë‹¤."

    # ë³‘ì› ì •ë³´ ì‘ë‹µ
    summarized_results = [
        f"{item.get('facility_name', 'ì•Œ ìˆ˜ ì—†ìŒ')}: {item.get('floor_info', 'ì •ë³´ ì—†ìŒ')} | {item.get('location', 'ì •ë³´ ì—†ìŒ')} | {item.get('service_description', 'ì •ë³´ ì—†ìŒ')}"
        for item in search_results[:5]
    ]
    search_results_str = "\n".join(summarized_results)

    messages=[
        {
            "role": "system",
            "content": f"""
                ë„ˆëŠ” ì‚¼ì„±ë³‘ì›ì˜ ì˜ë£Œ ì‹œì„¤ ì •ë³´ë¥¼ ì•ˆë‚´í•˜ëŠ” AIì•¼. ì´ë¦„ì€ 'í•˜í”¼'ë¼ê³  í•´.
                ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´í•´í•˜ê³ , ê²€ìƒ‰ëœ ë³‘ì› ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ì œê³µí•´.
                ë˜í•œ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ë‹¤ì–‘í•œ ì‘ë‹µì„ í•  ìˆ˜ ìˆì–´.

                ì‘ë‹µ ê·œì¹™:
                1. **ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„**í•´ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ì•„.
                2. **ê²€ìƒ‰ëœ ë³‘ì› ì •ë³´ê°€ ìˆìœ¼ë©´**, í•´ë‹¹ ë‚´ìš©ì„ ì •í™•í•œ ë†’ì„ë§ë¡œ ì „ë‹¬í•´.
                3. **ê²€ìƒ‰ëœ ë³‘ì› ì •ë³´ì™€ ì™¸ë¶€ ê²€ìƒ‰ ì •ë³´ê°€ ëª¨ë‘ ì—†ìœ¼ë©´**, "í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ê³ , ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„í•´.
                4. **ì™¸ë¶€ ê²€ìƒ‰ ì •ë³´ê°€ ìˆìœ¼ë©´**, í•´ë‹¹ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„í•´.
                4. **ì‚¬ìš©ìê°€ ë‚ ì”¨ë¥¼ ë¬¼ì–´ë³¼ ê²½ìš°**, 'ì„œìš¸'ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•´.
                5. **ì‘ë‹µì€ í•­ìƒ ë†’ì„ë§ë¡œ ì‘ì„±**í•´.

                í˜„ì¬ ì œê³µí•  ìˆ˜ ìˆëŠ” ë³‘ì› ì •ë³´:
                {search_results_str if search_results else "í˜„ì¬ ì œê³µí•  ìˆ˜ ìˆëŠ” ë³‘ì› ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}
                ì™¸ë¶€ ê²€ìƒ‰ ì •ë³´:
                {external_search if external_search else "í˜„ì¬ ì œê³µí•  ìˆ˜ ìˆëŠ” ì™¸ë¶€ ê²€ìƒ‰ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."}

                ì™„ì„±ëœ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€ì„ í•˜ì.
            """
        }
    ]

    messages.extend(history)
    messages.append({"role": "user", "content": query})

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        max_tokens=150,
        temperature=0.7
    )

    # OepnAI APIë¡œ ìƒì„±ëœ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
    response_text = response.choices[0].message.content

    # ê²°ê³¼ í›„ì²˜ë¦¬
    response_text = trim_to_complete_sentence(response_text)

    history.append({"role": "user", "content": query})
    history.append({"role": "assistant", "content": response_text})

    return response_text

# history ì´ˆê¸°í™” í•¨ìˆ˜
def clear_history():
    global history
    history = []
    print("ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ëŒ€í™”í˜• ì±—ë´‡ ì‹¤í–‰ í•¨ìˆ˜
def chat():
    print("ì±—ë´‡ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì¢…ë£Œí•˜ë ¤ë©´ 'exit'ì„ ì…ë ¥í•˜ì„¸ìš”.")

    while True:
        user_input = input("ì‚¬ìš©ì: ")

        if user_input.lower() == 'exit':
            print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break



         #ì™¸ë¶€ ê²€ìƒ‰
        external_search= []

        # ìµœì í™”ëœ ê²€ìƒ‰ì–´ ìƒã…‡ì„±
        optimized_query = optimize_query(user_input)
        logging.info("ìµœì í™”ëœ ê²€ìƒ‰ì–´: ", optimized_query)

        # Google ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
        google_results = google_search("site:samsunghospital.com " , optimized_query)
        if google_results:
            logging.info("Google ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€")
            external_search.extend(google_results)  # ê¸°ì¡´ ê²€ìƒ‰ ê²°ê³¼ì— ì¶”ê°€
            print("ğŸ” Google ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")

        # tavily_search_answer = tavily_search(optimized_query)
        # if tavily_search_answer:
        #     logging.info("tavily ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€")
        #     external_search.extend(tavily_search_answer)

        response = generate_response(user_input, search_hospital_info(user_input), external_search)
        print(response)
if __name__ == "__main__":
    chat()
